{"cells":[{"cell_type":"markdown","id":"804e5322-3694-4220-9f11-0261756a5024","metadata":{"id":"804e5322-3694-4220-9f11-0261756a5024"},"source":["# Insulin Intake Prediction using LightGBM\n","\n","Light Gradient-Boosting Machine, is an open-source distributed gradient-boosting framework for machine learning, originally developed by Microsoft."]},{"cell_type":"markdown","id":"fWuPu-hBOp_e","metadata":{"id":"fWuPu-hBOp_e"},"source":["# Mount the google drive"]},{"cell_type":"code","execution_count":5,"id":"eIpHCAmQAPUp","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":712,"status":"ok","timestamp":1733373619756,"user":{"displayName":"Geetha Krishna","userId":"13493738348547415301"},"user_tz":300},"id":"eIpHCAmQAPUp","outputId":"c472a7f5-c59a-43e1-d752-ac4308d37189"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","[Errno 2] No such file or directory: '/content/drive/MyDrive/ColabNotebooks/4_Trimester_Fall2024/Project/Codes/'\n","/content\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/ColabNotebooks/4_Trimester_Fall2024/Project/Codes/\n"]},{"cell_type":"markdown","id":"2wZ-k4_oOyM4","metadata":{"id":"2wZ-k4_oOyM4"},"source":["# Import required packages"]},{"cell_type":"code","execution_count":3,"id":"c9594108-c51e-4cf8-bdf3-df81e488fe8c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c9594108-c51e-4cf8-bdf3-df81e488fe8c","executionInfo":{"status":"ok","timestamp":1733373566341,"user_tz":300,"elapsed":6944,"user":{"displayName":"Geetha Krishna","userId":"13493738348547415301"}},"outputId":"3e894949-3092-433f-b61e-496ce0907d8e"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n"]}],"source":["import lightgbm as lgb #Imports the LightGBM library for gradient boosting models.\n","import pandas as pd # Imports pandas for data manipulation and analysis.\n","import numpy as np # Imports NumPy for numerical operations and handling arrays.\n","import matplotlib.pyplot as plt  # Imports Matplotlib for creating visualizations.\n","from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report # Imports evaluation metrics for model performance.\n","from sklearn.model_selection import train_test_split #  Imports a function to split data into training and testing sets.\n","from sklearn.preprocessing import label_binarize #  Imports a function to convert categorical labels into a binary format.\n","import seaborn as sns # Imports Seaborn for enhanced data visualization.\n","from sklearn.metrics import roc_curve, auc # Imports functions to compute and plot the ROC curve and calculate the Area Under the Curve (AUC).\n","from imblearn.over_sampling import SMOTE # Imports the SMOTE technique for handling class imbalance by oversampling minority classes."]},{"cell_type":"markdown","id":"BRpbEqAaO3MG","metadata":{"id":"BRpbEqAaO3MG"},"source":["# Load the dataset and cleanse the data"]},{"cell_type":"code","execution_count":4,"id":"3308b65a-4e03-43d2-9254-3223d2850ab5","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"id":"3308b65a-4e03-43d2-9254-3223d2850ab5","executionInfo":{"status":"error","timestamp":1733373566440,"user_tz":300,"elapsed":102,"user":{"displayName":"Geetha Krishna","userId":"13493738348547415301"}},"outputId":"7d568d2e-2675-4aa2-e4d6-d340909cf875"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'diabetic_data_clean.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-4c31735d22be>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load your dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'diabetic_data_clean.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Reads the diabetic_data_clean.csv file into a pandas DataFrame named data for further data manipulation and analysis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'diabetic_data_clean.csv'"]}],"source":["# Load your dataset\n","data = pd.read_csv('diabetic_data_clean.csv')\n","# Reads the diabetic_data_clean.csv file into a pandas DataFrame named data for further data manipulation and analysis."]},{"cell_type":"code","execution_count":null,"id":"aG8HyBCHBWLz","metadata":{"id":"aG8HyBCHBWLz","executionInfo":{"status":"aborted","timestamp":1733373566441,"user_tz":300,"elapsed":32249,"user":{"displayName":"Geetha Krishna","userId":"13493738348547415301"}}},"outputs":[],"source":["data.head(5)"]},{"cell_type":"code","execution_count":null,"id":"530b7a54-ca79-4136-80d9-888fce03da26","metadata":{"id":"530b7a54-ca79-4136-80d9-888fce03da26","executionInfo":{"status":"aborted","timestamp":1733373566578,"user_tz":300,"elapsed":4,"user":{"displayName":"Geetha Krishna","userId":"13493738348547415301"}}},"outputs":[],"source":["# Here we drop irrelevant columns and handle categorical variables\n","data = data.drop(columns=['encounter_id', 'patient_nbr', 'readmitted'])  # Drop non-predictive columns\n","# Removes the encounter_id, patient_nbr, and readmitted columns from the DataFrame data, as these columns are considered non-predictive for the analysis."]},{"cell_type":"code","execution_count":null,"id":"c9ff033e-536b-4682-b26e-972dbfbaa42d","metadata":{"id":"c9ff033e-536b-4682-b26e-972dbfbaa42d","executionInfo":{"status":"aborted","timestamp":1733373566579,"user_tz":300,"elapsed":4,"user":{"displayName":"Geetha Krishna","userId":"13493738348547415301"}}},"outputs":[],"source":["# Define features and target variable\n","X = data.drop(columns=['insulin'])  # Features. Creates a new DataFrame X containing all features except the insulin column, which will be used as input features for the model.\n","y = data['insulin']  # Target variable. Extracts the insulin column from data and assigns it to y, representing the target variable the model will predict."]},{"cell_type":"code","execution_count":null,"id":"c7702a48-2c9c-49d2-8791-395cbc087b56","metadata":{"id":"c7702a48-2c9c-49d2-8791-395cbc087b56","executionInfo":{"status":"aborted","timestamp":1733373566579,"user_tz":300,"elapsed":4,"user":{"displayName":"Geetha Krishna","userId":"13493738348547415301"}}},"outputs":[],"source":["# One-hot encoding for categorical variables\n","X = pd.get_dummies(X, drop_first=True)\n","# Converts categorical features in X into one-hot encoded binary columns, dropping the first category to avoid multicollinearity.\n","# This transforms categorical data into a format suitable for machine learning models."]},{"cell_type":"code","execution_count":null,"id":"8bf1eb36-9a10-4697-828f-73460bc8d67a","metadata":{"id":"8bf1eb36-9a10-4697-828f-73460bc8d67a","executionInfo":{"status":"aborted","timestamp":1733373566579,"user_tz":300,"elapsed":4,"user":{"displayName":"Geetha Krishna","userId":"13493738348547415301"}}},"outputs":[],"source":["# Handle class imbalance using SMOTE (Synthetic Minority Over-sampling Technique)\n","smote = SMOTE(random_state=42) # Initializes the SMOTE (Synthetic Minority Oversampling Technique) object to handle class imbalance by generating synthetic samples for the minority class, with a fixed random state for reproducibility.\n","X, y = smote.fit_resample(X, y) # Applies SMOTE to the feature matrix X and target vector y, creating a balanced dataset by oversampling the minority class. The result is a resampled dataset with balanced class distribution."]},{"cell_type":"markdown","id":"LVdD_uicPSIm","metadata":{"id":"LVdD_uicPSIm"},"source":["# Split the dataset to Train and Test Sets"]},{"cell_type":"code","execution_count":null,"id":"5bbd7ee1-2cde-4f5a-a59c-fd1052954165","metadata":{"id":"5bbd7ee1-2cde-4f5a-a59c-fd1052954165","executionInfo":{"status":"aborted","timestamp":1733373566579,"user_tz":300,"elapsed":4,"user":{"displayName":"Geetha Krishna","userId":"13493738348547415301"}}},"outputs":[],"source":["# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","# Splits the dataset X (features) and y (target) into training and testing sets, with 20% of the data allocated to testing.\n","# The random_state=42 ensures reproducibility by controlling the random shuffling of data."]},{"cell_type":"code","execution_count":null,"id":"87407258-a6eb-456d-b644-8628e9dae18c","metadata":{"id":"87407258-a6eb-456d-b644-8628e9dae18c","executionInfo":{"status":"aborted","timestamp":1733373566579,"user_tz":300,"elapsed":3,"user":{"displayName":"Geetha Krishna","userId":"13493738348547415301"}}},"outputs":[],"source":["# Create LightGBM dataset\n","train_data = lgb.Dataset(X_train, label=y_train) # Converts the training features X_train and labels y_train into a LightGBM-specific dataset object (train_data) for model training.\n","test_data = lgb.Dataset(X_test, label=y_test, reference=train_data) # Converts the testing features X_test and labels y_test into a LightGBM dataset (test_data) for evaluation, using train_data as a reference to maintain consistent handling of features."]},{"cell_type":"markdown","id":"A_dYKq0IQY5H","metadata":{"id":"A_dYKq0IQY5H"},"source":["# Set LightGBM parameters"]},{"cell_type":"code","execution_count":null,"id":"07cb506f-c999-4b8a-942d-045ab048edbf","metadata":{"id":"07cb506f-c999-4b8a-942d-045ab048edbf","executionInfo":{"status":"aborted","timestamp":1733373566580,"user_tz":300,"elapsed":32386,"user":{"displayName":"Geetha Krishna","userId":"13493738348547415301"}}},"outputs":[],"source":["# Set LightGBM parameters for classification\n","params = {\n","    'objective': 'multiclass',  # Specifies that the task is a multiclass classification problem. Use 'binary' if the target variable (insulin) has only two categories.\n","    'metric': 'multi_logloss',  # Defines the evaluation metric as the multi-class logarithmic loss. For binary classification, use 'binary_logloss'.\n","    'boosting_type': 'gbdt', # Uses Gradient Boosting Decision Trees (GBDT) as the boosting method, which is the default boosting type in LightGBM.\n","    'learning_rate': 0.05,  # Slightly higher learning rate for better convergence. Controls the step size in updating weights. A lower learning rate improves generalization but requires more iterations.\n","    'num_leaves': 64,  # Increased number of leaves for more complex models. Sets the maximum number of leaves in each tree. Increasing this allows for more complex models but can lead to overfitting if too high.\n","    'max_depth': 10,  # Set a maximum depth to prevent overfitting. Limits the depth of the trees to control model complexity and prevent overfitting.\n","    'min_data_in_leaf': 50,  # Minimum number of data in a leaf. Sets the minimum number of samples a leaf must have to ensure that leaves donâ€™t become too small, reducing the risk of overfitting.\n","    'verbose': -1, # Suppresses detailed output logs during training.\n","    'num_class': len(y.unique())  # Set the number of classes if multiclass. Automatically sets the number of output classes based on the unique values in the target variable y (necessary for multiclass classification).\n","}"]},{"cell_type":"markdown","id":"nv-z0SCWQeSB","metadata":{"id":"nv-z0SCWQeSB"},"source":["# Set early stopping and train the model"]},{"cell_type":"code","execution_count":null,"id":"81969056-a27e-450d-aab5-3788d692c2a3","metadata":{"id":"81969056-a27e-450d-aab5-3788d692c2a3","executionInfo":{"status":"aborted","timestamp":1733373566580,"user_tz":300,"elapsed":32385,"user":{"displayName":"Geetha Krishna","userId":"13493738348547415301"}}},"outputs":[],"source":["# Train the model with early stopping to prevent overfitting\n","callbacks = [lgb.early_stopping(stopping_rounds=50)] # Sets an early stopping callback to halt training if the validation performance doesn't improve for 50 consecutive rounds, preventing overfitting and saving time.\n","\n","model = lgb.train(params, train_data, num_boost_round=1000, valid_sets=[test_data], callbacks=callbacks)\n","# Trains the LightGBM model using the specified parameters (params) and the train_data for up to 1000 boosting rounds, while evaluating on test_data.\n","# The training stops early if performance plateaus, as determined by the early stopping callback."]},{"cell_type":"markdown","id":"GMJ3RUJFQmgw","metadata":{"id":"GMJ3RUJFQmgw"},"source":["# Make predictions"]},{"cell_type":"code","execution_count":null,"id":"cfafd9c7-44c4-44fe-b7bb-fe4216cee089","metadata":{"id":"cfafd9c7-44c4-44fe-b7bb-fe4216cee089","executionInfo":{"status":"aborted","timestamp":1733373566580,"user_tz":300,"elapsed":32385,"user":{"displayName":"Geetha Krishna","userId":"13493738348547415301"}}},"outputs":[],"source":["# Make predictions\n","y_pred_proba = model.predict(X_test)  # Get predicted probabilities\n","# Uses the trained LightGBM model to predict the probabilities for each class for the test set X_test.\n","# The output, y_pred_proba, contains the predicted probabilities for each class, rather than hard classifications."]},{"cell_type":"code","execution_count":null,"id":"905b7326-271e-44d8-9980-b31f4b243f8b","metadata":{"id":"905b7326-271e-44d8-9980-b31f4b243f8b","executionInfo":{"status":"aborted","timestamp":1733373566580,"user_tz":300,"elapsed":32384,"user":{"displayName":"Geetha Krishna","userId":"13493738348547415301"}}},"outputs":[],"source":["# For multiclass classification, take the class with the highest probability\n","y_pred_class = y_pred_proba.argmax(axis=1)\n","# Converts the predicted probabilities y_pred_proba into class predictions by selecting the class with the highest probability for each sample.\n","# The argmax(axis=1) function returns the index of the maximum value along each row (representing the class with the highest probability), resulting in y_pred_class, the predicted class labels."]},{"cell_type":"markdown","id":"rRYBfy55Qx8y","metadata":{"id":"rRYBfy55Qx8y"},"source":["# Calcualte and print model metrics"]},{"cell_type":"code","execution_count":null,"id":"0908d5e8-9148-4030-ba57-ec52bb1daf26","metadata":{"id":"0908d5e8-9148-4030-ba57-ec52bb1daf26","executionInfo":{"status":"aborted","timestamp":1733373566580,"user_tz":300,"elapsed":32384,"user":{"displayName":"Geetha Krishna","userId":"13493738348547415301"}}},"outputs":[],"source":["# Calculate metrics\n","accuracy = accuracy_score(y_test, y_pred_class) # Calculates the accuracy of the model by comparing the predicted class labels (y_pred_class) with the true labels (y_test). Accuracy is the proportion of correct predictions.\n","f1 = f1_score(y_test, y_pred_class, average='weighted')  # Computes the F1 score with weighted averaging, which considers the imbalance in the class distribution. The F1 score is the harmonic mean of precision and recall, providing a balance between the two metrics.\n","roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')  # Calculates the ROC AUC score for multiclass classification using the one-vs-rest (OvR) approach. It measures the model's ability to distinguish between classes, with a higher value indicating better performance."]},{"cell_type":"code","execution_count":null,"id":"2ee0a367-1c88-41e2-a08b-17c756b4f106","metadata":{"id":"2ee0a367-1c88-41e2-a08b-17c756b4f106","executionInfo":{"status":"aborted","timestamp":1733373566580,"user_tz":300,"elapsed":32384,"user":{"displayName":"Geetha Krishna","userId":"13493738348547415301"}}},"outputs":[],"source":["# Print metrics\n","print(f'Accuracy: {accuracy:.4f}')  # Prints the accuracy of the model, formatted to 4 decimal places.\n","print(f'F1 Score: {f1:.4f}') # Prints the F1 score with weighted averaging, formatted to 4 decimal places.\n","print(f'ROC AUC: {roc_auc:.4f}') # Prints the ROC AUC score for multiclass classification, formatted to 4 decimal places.\n","print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_class)) # Prints a detailed classification report showing precision, recall, F1 score, and support for each class in the test set."]},{"cell_type":"markdown","id":"p9NZ-DOeQ6Nv","metadata":{"id":"p9NZ-DOeQ6Nv"},"source":["# Generate and plot confusion matrix"]},{"cell_type":"code","execution_count":null,"id":"4e5308c4-8d57-46cc-8569-ec33505b3b2b","metadata":{"id":"4e5308c4-8d57-46cc-8569-ec33505b3b2b","executionInfo":{"status":"aborted","timestamp":1733373566580,"user_tz":300,"elapsed":32383,"user":{"displayName":"Geetha Krishna","userId":"13493738348547415301"}}},"outputs":[],"source":["# Generate confusion matrix\n","cm = confusion_matrix(y_test, y_pred_class)\n","\n","# Calculates the confusion matrix for the test set, comparing the true labels (y_test) with the predicted class labels (y_pred_class).\n","# The confusion matrix provides a summary of the model's performance, showing the counts of true positives, false positives, true negatives, and false negatives for each class."]},{"cell_type":"code","execution_count":null,"id":"15da8fd5-2da0-4af0-9ab6-30596b81944c","metadata":{"id":"15da8fd5-2da0-4af0-9ab6-30596b81944c","executionInfo":{"status":"aborted","timestamp":1733373566581,"user_tz":300,"elapsed":32384,"user":{"displayName":"Geetha Krishna","userId":"13493738348547415301"}}},"outputs":[],"source":["# Calculate percentage confusion matrix\n","cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n","\n","# Converts the confusion matrix cm into percentage values by normalizing each row (representing a class) so that the sum of each row equals 100%."]},{"cell_type":"code","execution_count":null,"id":"69d4b684-79fe-4289-a260-f7b8503a8b71","metadata":{"id":"69d4b684-79fe-4289-a260-f7b8503a8b71","executionInfo":{"status":"aborted","timestamp":1733373566581,"user_tz":300,"elapsed":32384,"user":{"displayName":"Geetha Krishna","userId":"13493738348547415301"}}},"outputs":[],"source":["# Define custom labels\n","custom_labels = ['No', 'Down', 'Steady', 'Up']  # Defines custom labels for the classes in the confusion matrix. These labels replace the default numerical labels.\n","\n","# Plot Confusion Matrix\n","plt.figure(figsize=(10, 8)) # Sets the figure size to 10x8 inches for better visibility of the confusion matrix plot.\n","plt.imshow(cm_percentage, interpolation='nearest', cmap=plt.cm.Blues) # Visualizes the confusion matrix cm_percentage as an image, using a blue color map for styling.\n","plt.title('Confusion Matrix (Percentage)') # Adds the title \"Confusion Matrix (Percentage)\" to the plot.\n","plt.colorbar() # Displays a color bar next to the matrix, showing the intensity scale of the colors.\n","\n","# Adjust ticks with custom labels\n","tick_marks = np.arange(len(custom_labels)) # Creates tick marks for the custom labels, one for each class.\n","plt.xticks(tick_marks, custom_labels, rotation=45) # Sets the x-axis labels (predicted labels) with the custom labels and rotates them 45 degrees for readability.\n","plt.yticks(tick_marks, custom_labels) # Sets the y-axis labels (true labels) with the custom labels.\n","\n","# Show percentage values on the matrix\n","thresh = cm_percentage.max() / 2.0 # Calculates a threshold for the text color: values above the threshold will be displayed in white, and values below will be displayed in black.\n","for i in range(cm_percentage.shape[0]): # Loops through each row of the confusion matrix to add the percentage values to the plot.\n","    for j in range(cm_percentage.shape[1]):\n","        plt.text(j, i, f'{cm_percentage[i, j]:.1f}%', ha='center', va='center', # Adds the percentage text to each cell in the matrix, with white or black color depending on the background intensity.\n","                 color='white' if cm_percentage[i, j] > thresh else 'black')\n","\n","plt.ylabel('True label') # Sets the label for the y-axis as \"True label\".\n","plt.xlabel('Predicted label') # Sets the label for the x-axis as \"Predicted label\".\n","plt.tight_layout() # Adjusts the layout of the plot to make sure labels and titles fit well within the figure.\n","plt.show() # Displays the plot."]},{"cell_type":"markdown","id":"ckReErjTOTdP","metadata":{"id":"ckReErjTOTdP"},"source":["# Plot Receiver-operating characteristic curve (ROC)"]},{"cell_type":"code","execution_count":null,"id":"d3132970-adfd-4801-8c13-60c8a88a9274","metadata":{"id":"d3132970-adfd-4801-8c13-60c8a88a9274","executionInfo":{"status":"aborted","timestamp":1733373566581,"user_tz":300,"elapsed":32383,"user":{"displayName":"Geetha Krishna","userId":"13493738348547415301"}}},"outputs":[],"source":["# Plot ROC curve for multiclass classification\n","# One-hot encode the true labels\n","y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n","# Binarizes the true labels y_test into a format suitable for multiclass ROC curve analysis, where each class is converted into a separate binary vector (one-hot encoding).\n","# This step is necessary because the roc_curve function requires binary labels for each class.\n","\n","fpr, tpr, roc_auc_dict = {}, {}, {} # Initializes empty dictionaries to store the False Positive Rate (FPR), True Positive Rate (TPR), and AUC for each class.\n","for i in range(y_test_bin.shape[1]): # Loops through each class (the number of columns in the binarized true labels y_test_bin).\n","    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i]) # Computes the False Positive Rate (FPR) and True Positive Rate (TPR) for each class using the roc_curve function. It compares the binarized true labels (y_test_bin[:, i]) with the predicted probabilities (y_pred_proba[:, i]) for the current class.\n","    roc_auc_dict[i] = auc(fpr[i], tpr[i]) # Calculates the Area Under the Curve (AUC) for each class using the auc function, which measures the model's ability to distinguish between classes.\n","\n","# Plot all ROC curves\n","plt.figure(figsize=(10, 8)) # Creates a new figure with a size of 10x8 inches for the ROC curve plot.\n","for i in range(y_test_bin.shape[1]): # Loops through each class again to plot the ROC curve for each class.\n","    plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc_dict[i]:.2f})') # Plots the ROC curve for the current class using the previously computed FPR and TPR. The AUC is displayed in the legend for each class.\n","\n","# Plot the diagonal line (random classifier)\n","plt.plot([0, 1], [0, 1], color='gray', linestyle='--') # Plots a diagonal line representing the performance of a random classifier (i.e., the line where the FPR and TPR are equal).\n","\n","# Customize the plot\n","plt.title('ROC Curve (Multiclass)') # Sets the title of the plot to \"ROC Curve (Multiclass)\".\n","plt.xlabel('False Positive Rate') #Labels the x-axis as \"False Positive Rate\".\n","plt.ylabel('True Positive Rate') # Labels the y-axis as \"True Positive Rate\".\n","plt.legend(loc='lower right') # Displays the legend in the lower right corner of the plot, showing the class labels and their corresponding AUC values.\n","plt.grid(True) # Adds a grid to the plot for better readability.\n","plt.tight_layout() # Adjusts the layout of the plot to ensure everything fits well, avoiding overlapping labels.\n","plt.show() # Displays the ROC curve plot."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":5}